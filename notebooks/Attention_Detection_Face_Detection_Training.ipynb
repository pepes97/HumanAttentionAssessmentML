{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Attention Detection - Face Detection Training.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7DEQG68JzSD"
      },
      "source": [
        "# Dependency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY0YTFifJ1oP"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path, sys\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, datasets, models, optimizers\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Add, Activation, MaxPooling2D, Dropout, Flatten, Dense, AveragePooling2D\n",
        "from tensorflow.keras import  Input\n",
        "from tensorflow.keras import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "\n",
        "import imutils\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import gdown\n",
        "\n",
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_dg6NGa3iKB"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs0ycmgd07Jx"
      },
      "source": [
        "gdown.download(\"https://drive.google.com/uc?export=download&id=1u57z2B_Kdwtzly1p0gEwm9bQ60AUeM7j\", \"./train.zip\", quiet=False) \n",
        "gdown.download(\"https://drive.google.com/uc?export=donwload&id=1-0uFU0xH2swwQXVE7uGR1tCa7dtkshgd\", \"./dev.zip\", quiet=False)\n",
        "gdown.download(\"https://drive.google.com/uc?export=download&id=1-5B1d2UJNQvqY1eFIr7_DT8NngMZNboR\", \"./test.zip\", quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtOTn_Gx3mZQ"
      },
      "source": [
        "# Extract features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7it5Tvh3lfA"
      },
      "source": [
        "if os.path.exists(\"./train.zip\"):\n",
        "    print(\"Extracting the archive\")\n",
        "    with zipfile.ZipFile('./train.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/localdata/\")\n",
        "    with zipfile.ZipFile('./dev.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/localdata/\")\n",
        "    with zipfile.ZipFile('./test.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/localdata/\")\n",
        "    print(\"Done\")\n",
        "    os.remove(\"./train.zip\")   \n",
        "    os.remove(\"./dev.zip\") \n",
        "    os.remove(\"./test.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZkBE5pSKG8D"
      },
      "source": [
        "Go to localdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZLRnMR0KIXL"
      },
      "source": [
        "os.chdir(\"/content/localdata/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgRHuecGII3T"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP_glG-GKKei"
      },
      "source": [
        "# Check items for classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv_wa2wuKOrK"
      },
      "source": [
        "print(\"***************\")\n",
        "print(\"**** TRAIN ****\")\n",
        "print(\"***************\")\n",
        "print()\n",
        "directory = \"./train\"\n",
        "l = os.listdir(directory)\n",
        "print(f\"num classes: {len(l)}\")\n",
        "l.sort()\n",
        "for c in l:\n",
        "  print(c+\": \"+str(len(os.listdir(directory+\"/\"+c))))\n",
        "\n",
        "print()\n",
        "print(\"***************\")\n",
        "print(\"***** DEV *****\")\n",
        "print(\"***************\")\n",
        "print()\n",
        "directory = \"./dev\"\n",
        "l = os.listdir(directory)\n",
        "print(f\"num classes: {len(l)}\")\n",
        "l.sort()\n",
        "for c in l:\n",
        "  print(c+\": \"+str(len(os.listdir(directory+\"/\"+c))))\n",
        "  \n",
        "print()\n",
        "print(\"***************\")\n",
        "print(\"***** TEST ****\")\n",
        "print(\"***************\")\n",
        "print()\n",
        "directory = \"./test\"\n",
        "l = os.listdir(directory)\n",
        "print(f\"num classes: {len(l)}\")\n",
        "l.sort()\n",
        "for c in l:\n",
        "  print(c+\": \"+str(len(os.listdir(directory+\"/\"+c))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R57_qGnyK61Z"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnbe0xwK8UE"
      },
      "source": [
        "class SSDataset():\n",
        "\n",
        "  def __init__(self,train, valid, test, batch, target_size, data_aug):\n",
        "\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        - train: path to the train file\n",
        "        - test: path to the test file\n",
        "        - batch: batch size\n",
        "        - target_size: dimension of images\n",
        "        - data_aug: boolean that we use for data augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    self.train_file = train\n",
        "    self.valid_file = valid\n",
        "    self.test_file = test\n",
        "    self.batch_size = batch\n",
        "    self.target_size = target_size\n",
        "    self.data_aug = data_aug\n",
        "    self.train_generator, self.valid_generator, self.test_generator = self.create_dataset()\n",
        "\n",
        "  def create_dataset(self):\n",
        "      \"\"\"\n",
        "        creation of the dataset, divided in train, dev and test\n",
        "      \"\"\"\n",
        "\n",
        "      if self.data_aug:\n",
        "          train_data = ImageDataGenerator(\n",
        "              rescale = 1. / 255, # convert from uint8 to float32 in range 0,1\n",
        "              brightness_range=[0.3,1.5]\n",
        "          )\n",
        "      else:\n",
        "          train_data = ImageDataGenerator(\n",
        "              rescale = 1. / 255, # convert from uint8 to float32 in range 0,1\n",
        "          )\n",
        "\n",
        "      train_generator = train_data.flow_from_directory(\n",
        "          directory=self.train_file,\n",
        "          target_size=self.target_size,\n",
        "          color_mode=\"rgb\",\n",
        "          batch_size=self.batch_size,\n",
        "          class_mode=\"categorical\",\n",
        "          shuffle=True, \n",
        "      )\n",
        "\n",
        "      valid_data = ImageDataGenerator(\n",
        "          rescale = 1. / 255)\n",
        "      \n",
        "      valid_generator = valid_data.flow_from_directory(\n",
        "          directory=self.valid_file, \n",
        "          target_size=self.target_size,\n",
        "          batch_size=self.batch_size,\n",
        "          color_mode=\"rgb\",\n",
        "          shuffle=False,\n",
        "          class_mode='categorical') # set as validation data\n",
        "\n",
        "      test_datagen = ImageDataGenerator(\n",
        "          rescale = 1. / 255)\n",
        "\n",
        "      test_generator = test_datagen.flow_from_directory(\n",
        "          directory=self.test_file,\n",
        "          target_size=self.target_size,\n",
        "          color_mode=\"rgb\",\n",
        "          batch_size=self.batch_size,\n",
        "          class_mode=\"categorical\",\n",
        "          shuffle=False\n",
        "      )\n",
        "\n",
        "      return train_generator, valid_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdZmYrLT94RC"
      },
      "source": [
        "Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPE6-iclK_SH"
      },
      "source": [
        "data_aug = True\n",
        "target_size =(128, 128)\n",
        "batch_size = 64\n",
        "\n",
        "train = \"./train\"\n",
        "valid = \"./dev\"\n",
        "test = \"./test\"\n",
        "\n",
        "dataset = SSDataset(train,valid, test, batch_size, target_size, data_aug)\n",
        "train_generator, valid_generator, test_generator = dataset.train_generator, dataset.valid_generator, dataset.test_generator\n",
        "\n",
        "num_samples = train_generator.n\n",
        "num_classes = train_generator.num_classes\n",
        "input_shape = train_generator.image_shape\n",
        "classnames = [k for k,v in train_generator.class_indices.items()]\n",
        "\n",
        "print(\"\\nClasses:\\n%r\" %classnames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha6qsjffK9R2"
      },
      "source": [
        "# Show batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE-RToEiLCqe"
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "\n",
        "  \"\"\"\n",
        "    Args:\n",
        "      - image_batch: batch of images (not labels)\n",
        "      - label_batch: batch of labels \n",
        "  \"\"\"\n",
        "  \n",
        "  plt.figure(figsize=(12,12))\n",
        "  for n in range(16):\n",
        "      ax = plt.subplot(4,4,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      idx = np.where(label_batch[n] == 1)[0][0]\n",
        "      plt.title(classnames[idx])\n",
        "      plt.axis('off')\n",
        "\n",
        "image_batch, label_batch = next(train_generator)\n",
        "show_batch(image_batch, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rptzF8UkLE9S"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEuwC018LG7r"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhfeOAn5LIVx"
      },
      "source": [
        "class HParams():\n",
        "  def __init__(self, input_shape, num_classes, lr, model_name, brightness, shift):\n",
        "\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        - input_shape: shape of images\n",
        "        - num_classes: number of classes\n",
        "        - lr: learning rate\n",
        "        - model_name: name of model\n",
        "    \"\"\"\n",
        "    self.brightness = brightness\n",
        "    self.shift = shift\n",
        "    self.shape = input_shape\n",
        "    self.num_classes = num_classes\n",
        "    self.lr = lr\n",
        "    self.optimizer = optimizers.Adam(self.lr)\n",
        "    self.loss_fn = 'categorical_crossentropy'\n",
        "    self.metrics = ['accuracy']\n",
        "    self.drop_rate = 0.5\n",
        "    self.n_res_net_blocks = 3\n",
        "    self.n_paths = 4\n",
        "    self.model_name = model_name #allowed values: Xception, ResNet, ResNeXt, VGG16, VGG19\n",
        "\n",
        "params = HParams(input_shape, num_classes, 0.00001, \"VGG16\", True, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNuDduJBLT85"
      },
      "source": [
        "## Pretrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtyYYlUtLWE4"
      },
      "source": [
        "class PretrainedModel():\n",
        "  def __init__(self,name, trainable):\n",
        "\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        - name: name of pretrained model\n",
        "        - trainable: boolean used to indicate if layers of pretrained model are freezed or trained\n",
        "    \"\"\"\n",
        "    \n",
        "    self.name = name\n",
        "    self.trainable = trainable\n",
        "    self.model = self.build_model()\n",
        "  \n",
        "  def build_model(self):\n",
        "\n",
        "    if self.name == \"Xception\":\n",
        "      base_model = keras.applications.Xception(\n",
        "          weights='imagenet',\n",
        "          input_shape=input_shape,\n",
        "          include_top=False\n",
        "      )\n",
        "    elif self.name == \"ResNet\":\n",
        "      base_model = keras.applications.ResNet152V2(\n",
        "          weights='imagenet',\n",
        "          input_shape=input_shape,\n",
        "          include_top=False\n",
        "      )\n",
        "    elif self.name == \"VGG16\":\n",
        "      base_model = keras.applications.VGG16(\n",
        "          weights='imagenet',\n",
        "          input_shape=input_shape,\n",
        "          include_top=False\n",
        "      )\n",
        "    else:\n",
        "      base_model = keras.applications.VGG19(\n",
        "          weights='imagenet',\n",
        "          input_shape=input_shape,\n",
        "          include_top=False\n",
        "      )\n",
        "\n",
        "    base_model.trainable = self.trainable\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # We freeze pretrained model weigths\n",
        "    x = base_model(inputs, training=True)\n",
        "\n",
        "    # Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "    x = keras.layers.Dropout(params.drop_rate)(x)\n",
        "    x = keras.layers.Dense(128, activation='relu')(x)\n",
        "    outputs = keras.layers.Dense(params.num_classes, activation=\"softmax\")(x)\n",
        "    ss_model = keras.Model(inputs, outputs, name=params.model_name)\n",
        "    ss_model.compile(loss=params.loss_fn, optimizer=params.optimizer, metrics=params.metrics)\n",
        "\n",
        "    return ss_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ2yp_F7LX2X"
      },
      "source": [
        "### Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7qlatALaU5"
      },
      "source": [
        "ss_model = PretrainedModel(params.model_name, True).model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5xB9GYLhwv"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRj5LbexLjCr"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "nome_prova = f\"{params.model_name}{input_shape}_lr{params.lr}_drop{params.drop_rate}_data_aug_{data_aug}_brightness_{params.brightness}_shift_{params.shift}_FACE_DETECTION_{datetime.now().strftime('%Y%m_%d_%H_%M_%S')}\"\n",
        "\n",
        "model_path = \"/content/training/checkpoints/\"+nome_prova+\"/\"\n",
        "logs_path = \"/content/training/tensorboard_logs/\"+nome_prova\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "  os.makedirs(model_path)\n",
        "\n",
        "if not os.path.exists(logs_path):\n",
        "  os.makedirs(logs_path)\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=model_path+'model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=logs_path)\n",
        "]\n",
        "\n",
        "history = ss_model.fit(train_generator, epochs=20, verbose=1, validation_data=valid_generator, callbacks=my_callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVODsvgELkr6"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ghicdyvLnLx"
      },
      "source": [
        "loss, acc = ss_model.evaluate(test_generator, verbose=1)\n",
        "print('Test loss: %f' %loss)\n",
        "print('Test accuracy: %f' %acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwZysTR8LoUB"
      },
      "source": [
        "# Show batch predict test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8E28nzkLp49"
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(12,12))\n",
        "  for n in range(36):\n",
        "      ax = plt.subplot(6,6,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      pred = ss_model(image_batch)\n",
        "      idx = np.where(label_batch[n] == 1)[0][0]\n",
        "      idx_pred = pred[n].numpy().argmax()\n",
        "      plt.title(f\"{classnames[idx]} -> {classnames[idx_pred]}\")\n",
        "      plt.axis('off')\n",
        "\n",
        "image_batch, label_batch = next(test_generator)\n",
        "show_batch(image_batch, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}